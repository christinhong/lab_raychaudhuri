
Software you will need:

- GATK
- Picard tools
- vcf tools
- samtools
- SNPiR scripts (from Piskol et al)

Things to edit or keep in mind in scripts:

- paths to software, input and output files, etc.
- I often use "gnu parallel" to parallelize jobs...not sure if you can use that in partners, may be yes as long as you include in the parallel cmd the bjob? (you can ask Kam)
- the scripts often depend on the directory structure in which I work. For example:
path_of_project/mapping/sample_name/subread(or mapper_name)/sample_name.bam 

##############################################
######          CALLING VARIANTS        ######
##############################################

#### Commands to call variants 76bp single-end bulk RNA-seq ####

## Working directory
cd /medpop/srlab/mgutierr/tofiPub/varCall

## Output directory
/medpop/srlab/mgutierr/tofiPub/varCall

## Copying and slightly modifying scripts from
/home/unix/mgutierr/work/rnaseq/cd4timelinepilot/variantCalling
#/medpop/srlab/cd4timelinepilot/rnaseq/141125_PR1504/variantCalling
#/home/unix/mgutierr/work/rnaseq/testCallVar

## Taking fastq files from
/medpop/srlab/mgutierr/tofiPub/*.fastq

## 1. Star 2-pass mapping
#		a. Using STAR generated genome in: /medpop/rnaseq/access/star_genome3
				(was generataed using sh run_star-prepare-reference.sh)		


# run_star-prepare-reference.sh
# Kamil Slowikowski
# July 18, 2014
#
# Modified by Maria, Nov 2014
# Prepare reference files needed to run the STAR read mapper, using observed splice-junctions from pass 1.

# sh run_star-prepare-reference-mergedSJs.sh directoryForOutputRefGenome fileWithMergedSpliceJunctions

#genome=/medpop/rnaseq/access/kam_ucsc_genome/genome.fa

#screen
#cd /medpop/rnaseq/access/mapping/140506_SN7001282_0527_AH0H0GADXX/CD5_S4_L002/hg19_2pass
#STAR --runMode genomeGenerate --genomeDir /medpop/rnaseq/access/mapping/140506_SN7001282_0527_AH0H0GADXX/CD5_S4_L002/hg19_2pass --genomeFastaFiles /humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta --sjdbFileChrStartEnd /medpop/rnaseq/access/mapping/140506_SN7001282_0527_AH0H0GADXX/CD5_S4_L002/SJ.out.tab --sjdbOverhang 75 --runThreadN 4

#regex="(14[a-zA-Z0-9_]+)/([a-zA-Z0-9]+_S[0-9]+_L[0-9]+)"
#/medpop/rnaseq/access/mapping/140506_SN7001282_0527_AH0H0GADXX/CD4_S2_L002/CD4_S2_L002_R1_001.fastq

#[[ $1 =~ $regex ]]
#project="${BASH_REMATCH[1]}"
#library="${BASH_REMATCH[2]}"

genome=/humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta

out=$1/GenomeForStarPass2
[[ ! -d $out ]] && mkdir -p $out

# STAR generates files in the current directory.
cd $out

log=$out/log.txt

opt=(
--runMode genomeGenerate
--genomeDir $out
--genomeFastaFiles $genome
--runThreadN 4
--sjdbFileChrStartEnd $2
--sjdbOverhang 75
)

STAR ${opt[*]} &> $log


#	 	b. First pass: Map reads to reference genome (output will be saved in star_pass1 folder, within each library folder)
#		c. Create reference genome with merged junctions from first pass of all samples
#		d. Second pass: map reads to new reference genome that has all observed splice junctions
##
## 2. Data pre-processing with Picard tools and GATK
# 		a. Add read groups, sort, and create index
#		b. Split'N'Trim and reassign mapping qualities
#		c. Base recalibration

sh try_pipeline_star2pass.sh


#!/bin/bash

#Variant Caller
#runs star pass 2 mapping
#runs pre-processing for GATK
#runs hapCaller by merging files by chromosome


#parameters to change
workingDir=/home/unix/mgutierr/work/rnaseq/cd4timelinepilot/tofiPub
mappingDir=/medpop/srlab/mgutierr/tofiPub/mapping
suffixSamples=SRR
listFastq=list_fastq.txt#assumes it is in working dir
numJobs=3
regExpr=regExpr.txt
#check ref star genome is still OK for run_star_pass1.sh

#shortcuts
parallel=/home/unix/slowikow/src/parallel-20140422/src/parallel

#STAR
#$parallel --xapply echo :::: list_fastq.txt $regExpr

#Align reads with STAR for each sample
$parallel -j$numJobs --xapply --eta 'sh run_star_pass1.sh' :::: $listFastq $regExpr

#!/usr/bin/env bash

# Kamil Slowikowski
# June  9, 2014
#
#Modif Maria Nov, 2014

fq="(\.fq|\.fastq)$"
if [[ $# != 2 || ! "$1" =~ $fq ]]
then
    echo "Received: $0 $@"
    echo "Usage: $0 SC10054_A01.end1.fq regExprFile"
    echo
    exit 1
fi
#[[ ! -e "$1" ]] && echo "FASTQ file not found $1" && exit 1

regex=$2
#/medpop/srlab/cd4timelinepilot/rnaseq/141125_PR1504/input/20141125-0hr-NT-20141014-IDX2-PR1504_S1_R1.fastq
[[ $1 =~ $regex ]]
basedir="${BASH_REMATCH[1]}"
library="${BASH_REMATCH[2]}"

echo $basedir
echo $library

out=$basedir/mapping/$library/starPass1
[[ ! -d $out ]] && mkdir -p $out

# STAR generates files in the current directory.
cd $out

opt=(
--genomeDir /medpop/rnaseq/access/star_genome3
--readFilesIn $1
--runThreadN 4
--genomeLoad LoadAndKeep
)

if [[ "$DRY_RUN" == "" ]]
then
    STAR ${opt[*]} &> log.txt
    # Convert SAM to BAM.
    sam=Aligned.out.sam
    bam=Aligned.out.bam
	[[ -e $sam ]] && samtools view -Sb -o $bam $sam && rm -f $sam
else
    echo "STAR ${opt[*]} &> log.txt"
    echo "samtools view -Sb -o Aligned.out.bam Aligned.out.sam"
    echo "rm -f Aligned.out.sam"
fi




#Merge the exon-exon junctions found for each sample into one file
nice -n20 perl ~/work/rnaseq/cd4timelinepilot/merge_SJ_pass1.pl $mappingDir/$suffixSamples*/starPass1/SJ.out.tab > $mappingDir/SJ.out.merged.tab

#Prepare new reference genome for star using exon junctions
sh run_star-prepare-reference-mergedSJs.sh $mappingDir $mappingDir/SJ.out.merged.tab

#Run STAR again for each sample using new ref genome	
$parallel -j$numJobs --xapply --eta 'sh run_star_pass2.sh' :::: $listFastq $regExpr

#!/usr/bin/env bash

# Kamil Slowikowski
# June  9, 2014
#
# Modif Maria Nov, 2014
# 

fq="(\.fq|\.fastq)$"
if [[ $# != 2 || ! "$1" =~ $fq ]]
then
    echo "Received: $0 $@"
    echo "Usage: $0 SC10054_A01.end1.fq regularExpression"
    echo
    exit 1
fi
#[[ ! -e "$1" ]] && echo "FASTQ file not found $1" && exit 1

#/medpop/srlab/mgutierr/tofiPub/SRR1552955.fastq
regex=$2

[[ $1 =~ $regex ]]
basedir="${BASH_REMATCH[1]}"
library="${BASH_REMATCH[2]}"

echo $basedir
echo $library

out=$basedir/mapping/$library/starPass2
[[ ! -d $out ]] && mkdir -p $out

genome=$basedir/mapping/GenomeForStarPass2

# STAR generates files in the current directory.
cd $out

opt=(
--genomeDir $genome
--readFilesIn $1
--runThreadN 4
--genomeLoad LoadAndKeep
)

if [[ "$DRY_RUN" == "" ]]
then
    STAR ${opt[*]} &> log.txt
    # Convert SAM to BAM.
    sam=Aligned.out.sam
    bam=Aligned.out.bam
	[[ -e $sam ]] && samtools view -Sb -o $bam $sam && rm -f $sam
else
    echo "STAR ${opt[*]} &> log.txt"
    echo "samtools view -Sb -o Aligned.out.bam Aligned.out.sam"
    echo "rm -f Aligned.out.sam"
fi

#Run GATK data pre-processing
ls -1 $mappingDir/$suffixSamples*/starPass2/*.bam > list_bams_starPass2.txt 

parallel -j3 --eta 'sh run_gatk_markDups.sh' :::: list_bams_starPass2.txt
#/home/unix/slowikow/src/parallel-20140422/src/parallel echo ::: A B C > abcFile



gatk=/home/unix/mgutierr/src/GATK
picard=/home/unix/mgutierr/src/picard-tools-1.119
genome=/humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta

infile=$1
#/medpop/srlab/cd4timelinepilot/rnaseq/141125_PR1504/mapping/20141125-0hr-NT-20141014-IDX2-PR1504_S1_R1/starPass2/Aligned.out.bam
#/medpop/rnaseq/access/mapping/140509_SN7001282_0537_BH0RGBADXX_Analysis/CD4_S5_L001/starPass2/Aligned.out.bam

out=$(dirname $1)/gatk
[[ ! -d $out ]] && mkdir -p $out
cd $out

#2. Add read groups, sort, mark duplicates, and create index
java -jar $picard/AddOrReplaceReadGroups.jar I=$infile O=rg_added_sorted.bam SO=coordinate RGID=readGroupID RGLB=libraryID RGPL=illumina RGPU=HiSeq RGSM=sampleID 

java -jar $picard/MarkDuplicates.jar I=rg_added_sorted.bam O=dedupped.bam  CREATE_INDEX=true VALIDATION_STRINGENCY=SILENT M=output.metrics

#need to index since MarkDups is not being ran in this case
#samtools index rg_added_sorted.bam

#3. Split'N'Trim and reassign mapping qualities

java -jar $gatk/GenomeAnalysisTK.jar -T SplitNCigarReads -R $genome -I dedupped.bam -o split.bam -rf ReassignOneMappingQuality -RMQF 255 -RMQT 60 -U ALLOW_N_CIGAR_READS

#5. Base Recalibration
java -Xmx4g -jar $gatk/GenomeAnalysisTK.jar -T BaseRecalibrator -I split.bam -R $genome -knownSites /humgen/gsa-hpprojects/GATK/bundle/current/hg19/dbsnp_138.hg19.vcf -knownSites /humgen/gsa-hpprojects/GATK/bundle/current/hg19/1000G_phase1.snps.high_confidence.hg19.vcf -knownSites /humgen/gsa-hpprojects/GATK/bundle/current/hg19/Mills_and_1000G_gold_standard.indels.hg19.vcf -o recal_data.table -nct 4

java -Xmx60g -jar $gatk/GenomeAnalysisTK.jar -T PrintReads -R $genome -I split.bam -BQSR recal_data.table -o split-BQSR.bam -nct 4



## 3. Merging files and calling variants with Haplotype Caller
# (in the files that look like list_chrs.txt there are the chromosome numbers or letters)
# (there are many cmds because I tried different approaches, since it takes a long time for each chr)
		a. Merge per chromosome, sort, index and call variants
		#tried all first for chr22
		#samtools merge -R chr22 /medpop/srlab/cd4timelinepilot/rnaseq/141125_PR1504/mapping/gatkMergedChrs/chr22.bam /medpop/srlab/cd4timelinepilot/rnaseq/141125_PR1504/mapping/201*/starPass2/gatk/split-BQSR.bam
		
		#lorax
		screen
		#parallel -j2 --eta 'sh run_merge_chr_and_HapCall.sh' :::: list_chrs_1.txt
	
		parallel -S 3/tigger,2/lorax,3/piglet --eta 'sh run_merge_chr_and_HapCall.sh' :::: list_chrs.txt
		
		parallel -j2 --eta 'sh run_merge_chr_and_HapCall.sh' :::: list_chrs.txt
		
		#lorax
		screen
		parallel -j2 --eta 'sh run_merge_chr_and_HapCall.sh' :::: list_chrs_1.txt
		
		#piglet
		screen
		parallel -j3 --eta 'sh run_merge_chr_and_HapCall.sh' :::: list_chrs_2.txt
		
		#tigger
		screen
		parallel -j3 --eta 'sh run_merge_chr_and_HapCall.sh' :::: list_chrs_3.txt
		
		
outdir=/medpop/srlab/mgutierr/tofiPub/mapping/gatkMergedChrs/

#chromosome to process
chr=chr$1

#merge all files from the individual in turn for the input chromosome
samtools merge -R $chr $outdir/$chr.bam /medpop/srlab/mgutierr/tofiPub/mapping/SR*/starPass2/gatk/split-BQSR.bam

#sort and index the chromosome file
samtools sort $outdir/$chr.bam $outdir/$chr.sorted
samtools index $outdir/$chr.sorted.bam

#call variants with HaplotypeCaller
java -Xmx50g -jar  /home/unix/mgutierr/src/GATK/GenomeAnalysisTK.jar -T HaplotypeCaller -R /humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta -I $outdir/$chr.sorted.bam -recoverDanglingHeads -dontUseSoftClippedBases -stand_call_conf 20.0 -stand_emit_conf 20.0 -o $outdir/output.$chr.vcf -nct 40 &> $outdir/hapCall.$chr.log		

		
		
		b. Move output to common folder
		
		cd /medpop/srlab/mgutierr/tofiPub/mapping/gatkMergedChrs
		mv output.chr* ../../varCall/rawPerChr/
		mv hapCall.chr* ../../varCall/rawPerChr/

## Working directory
cd /medpop/srlab/mgutierr/tofiPub/varCall
		
#		c. Concatenate vcf files of all chrs into one

		vcf-concat rawPerChr/output.chr1.vcf rawPerChr/output.chr2.vcf rawPerChr/output.chr3.vcf rawPerChr/output.chr4.vcf rawPerChr/output.chr5.vcf rawPerChr/output.chr6.vcf rawPerChr/output.chr7.vcf rawPerChr/output.chr8.vcf rawPerChr/output.chr9.vcf rawPerChr/output.chr1{0,1,2,3,4,5,6,7,8,9}.vcf rawPerChr/output.chr20.vcf rawPerChr/output.chr21.vcf rawPerChr/output.chr22.vcf rawPerChr/output.chrX.vcf rawPerChr/output.chrY.vcf > output.all_chrs.raw.sorted.vcf

		#vcf-concat rawPerChr/output.chr*.vcf > output.all_chrs.raw.vcf

## 4. Filtering

	sh try_pipeline_filtVars.sh

#!/bin/bash

## Working directory
workingDir=/medpop/srlab/mgutierr/tofiPub/varCall
genome=/humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta
gatk=/home/unix/mgutierr/src/GATK
mappingDir=/medpop/srlab/mgutierr/tofiPub/mapping
suffixSamples=SRR
scripts=/home/unix/mgutierr/work/rnaseq/cd4timelinepilot/scripts
parallel=/home/unix/slowikow/src/parallel-20140422/src/parallel

cd $workingDir
		
#		c. Concatenate vcf files of all chrs into one

vcf-concat rawPerChr/output.chr1.vcf rawPerChr/output.chr2.vcf rawPerChr/output.chr3.vcf rawPerChr/output.chr4.vcf rawPerChr/output.chr5.vcf rawPerChr/output.chr6.vcf rawPerChr/output.chr7.vcf rawPerChr/output.chr8.vcf rawPerChr/output.chr9.vcf rawPerChr/output.chr1{0,1,2,3,4,5,6,7,8,9}.vcf rawPerChr/output.chr20.vcf rawPerChr/output.chr21.vcf rawPerChr/output.chr22.vcf rawPerChr/output.chrX.vcf rawPerChr/output.chrY.vcf > output.all_chrs.raw.sorted.vcf

## 4. Filtering
		#a. SNPcluster filter
java -jar $gatk/GenomeAnalysisTK.jar -T VariantFiltration -R $genome  -V output.all_chrs.raw.sorted.vcf -window 35 -cluster 3 -o output.all_chrs.filtSNPclstr.vcf &> snpClstr.log
		
#b. Piskol et al filters

if [[ 1 =~ 2 ]]
then

	
cp -r ~/work/rnaseq/access/variantCalling/SNPiR .	
cd SNPiR
		
### Step 2. Convert VCF format to theirs and filter low qual variants

	#rm indels from vcf file

vcftools --vcf ../output.all_chrs.raw.sorted.vcf --remove-indels --recode --recode-INFO-all --out ../output.all_chrs.raw.sorted.rmIndel &> rmIndels.log

sh convertVCF.sh ../output.all_chrs.raw.sorted.rmIndel.recode.vcf ../output.all_chrs.rmIndel.txt 20

#This one did not work las time, so I will skip to next while merging is done (in tigger)
#### Step 3. Remove mismatches in first 6 bp of reads: 
#screen
#samtools merge $mappingDir/gatkMergedChrs/rg_added_sorted.mergedAllChrs.bam $mappingDir/$suffixSamples*/starPass2/gatk/rg_added_sorted.bam
#use bam file in which reads haven't passed by the  split thingy and probably haven't messed up cigar strngs
#perl filter_mismatch_first6bp.pl -infile /home/unix/mgutierr/work/rnaseq/access/variantCalling/piskolFilts/output.gatk.rmIndel.SNPiR.txt -outfile /home/unix/mgutierr/work/rnaseq/access/variantCalling/piskolFilts/output.gatk.rmIndel.SNPiR.rmhex.txt -bamfile /medpop/rnaseq/access/mapping/mergedGATKbams/rg_added_sorted.mergedAllChrs.bam


#Step 4. Use bedtools to remove sites in repetitive regions based on RepeatMasker annotation
awk '{print $1"\t"$2-1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6}' ../output.all_chrs.rmIndel.txt > ../output.all_chrs.rmIndel.bed
intersectBed -a ../output.all_chrs.rmIndel.bed -b /medpop/srlab/mgutierr/GFs/RepeatMasker_UCSCtab_hg19_Nov2014.bed -v > ../output.all_chrs.rmIndel.rmsk.bed
awk '{print $1"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7}' ../output.all_chrs.rmIndel.rmsk.bed > ../output.all_chrs.rmIndel.rmsk.txt

echo "Done with removing snps in repeats..."
#Further Filtering
#Step 1. Filter intronic candidates that are within 4 bp of splicing junctions: perl filter_intron_near_splicejuncts.pl
perl filter_intron_near_splicejuncts.pl -infile ../output.all_chrs.rmIndel.rmsk.txt -outfile ../output.all_chrs.rmIndel.rmsk.rmintron.txt -genefile UCSCgenes_knowGene_hg19_Nov2014.SNPiRformat.txt

echo "Done with filtering out snps in intronic near splice junctions..."

#Step 2. Filter candidates in homopolymer runs: perl filter_homopolymer_nucleotides.pl
perl filter_homopolymer_nucleotides.pl -infile ../output.all_chrs.rmIndel.rmsk.rmintron.txt -outfile ../output.all_chrs.rmIndel.rmsk.rmintron.rmhom.txt -refgenome $genome

echo "Done filtering out homopolymer runs..."
	
			##skipping BLAT step

#Step 4. Use bedtools to separate out candidates that are known RNA editing sites
awk '{print $1"\t"$2-1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6}' ../output.all_chrs.rmIndel.rmsk.rmintron.rmhom.txt > ../output.all_chrs.rmIndel.rmsk.rmintron.rmhom.bed
intersectBed -a ../output.all_chrs.rmIndel.rmsk.rmintron.rmhom.bed -b /medpop/srlab/mgutierr/GFs/darned_UCSCtab_Nov2014.bed -v > ../output.all_chrs.rmIndel.rmsk.rmintron.rmhom.rmedt.bed
awk '{print $1"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7}' ../output.all_chrs.rmIndel.rmsk.rmintron.rmhom.rmedt.bed > ../output.all_chrs.rmIndel.rmsk.rmintron.rmhom.rmedt.txt

echo "Done filtering out RNA editing sites..."


		
	#done! (except step 3)
			#Apply Piskol filters to vcf file
			
perl $scripts/create_piskolFilt_vcf.pl ../output.all_chrs.rmIndel.rmsk.rmintron.rmhom.rmedt.txt ../output.all_chrs.filtSNPclstr.vcf > ../output.all_chrs.filtSNPclstr.filtPiskol.vcf

echo "Done creating vcf with all used piskol Filts..."
	
		#c. GQ filter? This one I every time I try it doesn't really help, so not necessary
cd ..
perl $scripts/filter_vcf_byGQ.pl output.all_chrs.filtSNPclstr.filtPiskol.vcf > output.all_chrs.filtSNPclstr.filtPiskol.filtGQ.vcf

echo "Done filtering by genotype qual..."
		
#d. Each allele seen twice filter 
		
#need to run ASE pipeline on all biallelic variants
		
#select only bi allelic

java -Xmx2g -jar /home/unix/mgutierr/src/GATK/GenomeAnalysisTK.jar \
   -R /humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta \
   -T SelectVariants \
   --variant output.all_chrs.filtSNPclstr.filtPiskol.filtGQ.vcf \
   -o output.all_chrs.filtSNPclstr.filtPiskol.filtGQ.biallel.vcf \
   -restrictAllelesTo BIALLELIC

echo "Done selecting only biallelic with gatk..."

#keeping only variants that pass filters and are biallelic
java -Xmx2g -jar /home/unix/mgutierr/src/GATK/GenomeAnalysisTK.jar \
   -R /humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta \
   -T SelectVariants \
   --variant output.all_chrs.filtSNPclstr.filtPiskol.filtGQ.vcf \
   -o all_chrs.allFilts.vcf \
   -ef \
   -restrictAllelesTo BIALLELIC

echo "Done ballelic cmd 2..."

		
perl $scripts/filter_vcf_byHets.pl output.all_chrs.filtSNPclstr.filtPiskol.filtGQ.biallel.vcf > output.all_chrs.filtSNPclstr.filtPiskol.filtGQ.biallel.filtHom.vcf
			
echo "Done filtering  vcf by hets..."

fi

java -Xmx2g -jar /home/unix/mgutierr/src/GATK/GenomeAnalysisTK.jar \
   -R /humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta \
   -T SelectVariants \
   --variant output.all_chrs.filtSNPclstr.filtPiskol.vcf \
   -o output.all_chrs.filtSNPclstr.filtPiskol.biallel.vcf \
   -restrictAllelesTo BIALLELIC

#apply hom filter to  file below:
nice -n20 perl ~/work/rnaseq/access/scripts/filter_vcf_byHets.pl output.all_chrs.filtSNPclstr.filtPiskol.biallel.vcf > output.all_chrs.filtSNPclstr.filtPiskol.biallel.filtHom.vcf

#Get Hets with alleles seen in at least 2 samples
#nice -n 20 perl ~/work/rnaseq/access/scripts/create_easFilt_vcf.pl /home/unix/mgutierr/work/rnaseq/cd4timelinepilot/ASE/list_snps_as_min2.txt /medpop/srlab/cd4timelinepilot/rnaseq/141125_PR1504/variantCalling/output.all_chrs.filtSNPclstr.filtPiskol.biallel.filtHom.vcf > /medpop/srlab/cd4timelinepilot/rnaseq/141125_PR1504/variantCalling/output.all_chrs.filtSNPclstr.filtPiskol.biallel.filtHom.filtEAS2.vcf

#Get hets concordant with dbSNP
 java -Xmx2g -jar /home/unix/mgutierr/src/GATK/GenomeAnalysisTK.jar \
 	-R /humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta \
   -T SelectVariants \
   --variant output.all_chrs.filtSNPclstr.filtPiskol.biallel.filtHom.vcf \
   --concordance /humgen/gsa-hpprojects/GATK/bundle/current/hg19/dbsnp_138.hg19.vcf \
   -o output.all_chrs.filtSNPclstr.filtPiskol.biallel.filtHom.dbsnp.vcf


grep "0/1" output.all_chrs.filtSNPclstr.filtPiskol.biallel.filtHom.dbsnp.vcf | grep PASS > hets_allFilts.vcf

perl $scripts/add_ids_vcf.pl hets_allFilts.vcf > hets_allFilts.ids.vcf

echo "Done getting hets with ids."

ls -1 output*.vcf > list_vcfs2eval.txt

$parallel -j7 --eta 'sh /home/unix/mgutierr/work/rnaseq/cd4timelinepilot/scripts/run_gatk_eval.sh' :::: list_vcfs2eval.txt

perl ~/work/rnaseq/access/scripts/parse_gatk_eval_report.pl summary_eval_1KGP.txt eval.*_1KGP
perl ~/work/rnaseq/access/scripts/parse_gatk_eval_report.pl summary_eval_dbsnp.txt eval.*_dbsnp
			

gatk=/home/unix/mgutierr/src/GATK
genome=/humgen/gsa-hpprojects/GATK/bundle/current/hg19/ucsc.hg19.fasta
dbsnp=/humgen/gsa-hpprojects/GATK/bundle/current/hg19/dbsnp_138.hg19.vcf
kg=/humgen/gsa-hpprojects/GATK/bundle/current/hg19/1000G_phase1.snps.high_confidence.hg19.vcf

infile=$1
#/home/unix/mgutierr/work/rnaseq/access/variantCalling/output.all_chrs.filtSNPclstr.filtSNPiR.GQ30.biallel.vcf

regex="(.*)/output\.all_chrs\.(.*)\.vcf"
[[ $1 =~ $regex ]]
base="${BASH_REMATCH[2]}"

outdir=$(dirname $1)
cd $outdir

nice -n20 java -Xmx2g -jar $gatk/GenomeAnalysisTK.jar -T VariantEval -R $genome -o eval.$base.gatkreport_dbsnp --dbsnp $dbsnp --eval:set1 $infile

nice -n20 java -Xmx2g -jar $gatk/GenomeAnalysisTK.jar -T VariantEval -R $genome -o eval.$base.gatkreport_1KGP --dbsnp $kg --eval:set1 $infile


#######




