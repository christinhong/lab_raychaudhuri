#!/bin/bash

#BSUB -cwd "/data/srlab/cmhong/data/2015-09_RNA_Hirahara-OShea_stat1-ASE"

#BSUB -u christin.cmh@gmail.com
#BSUB -J "ASECleanUp"
#BSUB -o aaa_RNA-ASE-02_output_%J.txt
#BSUB -e aaa_RNA-ASE-02_errors_%J.txt

#BSUB -q medium
#BSUB -n 2
#BSUB -M 2000
#BSUB -R 'rusage[mem=2000]'

# @ BSUB -w "done(370930)" # Delete @ to run.  Can use BSUB -w "done(job ID)" to set this script to run after the first completes.

# 2015-09 Note: Every computer/node on the ERISOne Raychaudhuri Lab cluster has 24 CPU/job slots and 100 GB RAM.  Limit per job is 40 GB.

	
#####

# Christin M. Hong
# Last modified: 2015-11
# Lab of Soumya Raychaudhuri, MD, PhD (Harvard Medical School)

# Bash script for allele-specific expression (ASE) analysis on human RNA-seq data.  Running on the ERISOne Partners cluster (LSF).
     # Adapted from Dr. Maria Gutierrez-Arcelus's scripts for allele-specific expression


#####

# INPUT AND RESOURCES

# 1) FASTQ files
          # Assumes FASTQ files are sorted by individual and every individual supplied the same number of samples (e.g. Samples #1-3 are all from Person 1, #4-6 from Person 2, etc.)  If this isn't the case, will need to organize samples beforehand for the GATK HaplotypeCaller.


# 2) Reference files (search script for context)
     # UCSC reference genome hg19 
     # Gencode annotations for hg19
     # GATK Resource Bundle for hg19 (https://www.broadinstitute.org/gatk/guide/article.php?id=1215)
          # ucsc.hg19.fasta
          # ucsc.hg19.fasta.fai
          # ucsc.hg19.dict
          # dbsnp_138.hg19.vcf
          # dbsnp_138.hg19.vcf.idx
          # 1000G_phase1.snps.high_confidence.hg19.vcf
          # 1000G_phase1.snps.high_confidence.hg19.vcf.idx
     # RepeatMasker_UCSCtab_hg19_Nov2014.sorted.bed
     # RepeatMasker_UCSCtab_hg19_Nov2014.sorted.bed.idx
     # UCSCgenes_knowGene_hg19_Nov2014.SNPiRformat.txt
     # darned_UCSCtab_Nov2014.bed
     # wgEncodeCrgMapabilityAlign75mer_lowMap.bed
     # EUR01_50bp_result_stats_05bias.bed
     # hg19ChrList2.txt


# 3) Apps and scripts listed in GLOBAL VARIABLES section


#####

# GLOBAL VARIABLES

# Experiment-specific
export pathWd=/data/srlab/cmhong/data/2015-09_RNA_Hirahara-OShea_stat1-ASE # Working directory (set in #BSUB option, line 3)
export fileInd=ASE01_aa_stat1-ind # Retain "ind." at end for compatibility with RNA-ASE-03 (output cleanup) script
export pathInd=all${fileInd}.${LSB_JOBINDEX}
export intFastqPerIndividual=3


# Job-specific
export intCPUs=2
export intRAMmax=2


# Paths and reference files
export pathRef=/data/srlab/cmhong/ref-hg19
export pathSubscripts=/data/srlab/cmhong/scripts/subscripts
export pathApps=/data/srlab/cmhong/apps
export fileRef=${pathRef}/ucsc.hg19.fasta
export fileChrList=${pathRef}/hg19ChrList2.txt
export fileDbsnp=${pathRef}/dbsnp_138.hg19.vcf
export file1000G=${pathRef}/1000G_phase1.snps.high_confidence.hg19.vcf
export pathStarRef=${pathRef}/STAR-hg19
export pathSubscriptsMaria=${pathSubscripts}/RNA-ASE_maria


# Apps and scripts with versions in their respective paths
export parallel=${pathApps}/parallel-20150822/src/parallel
export STAR=${pathApps}/STAR-STAR_2.4.2a/bin/Linux_x86_64_static/STAR
export picard=${pathApps}/picard-f24c400-broadinstitute/dist/picard.jar
export GATK=${pathApps}/gatk-3.4-46/GenomeAnalysisTK.jar
export SNPiR=${pathApps}/SNPiR # !!! MANUAL MODIFICATION REQUIRED !!!  See ASE02f08 section notes.
export subread=${pathApps}/subread-1.4.6-p4-Linux-x86_64/bin
export scriptASE=${pathSubscriptsMaria}/samase_modMGA.pl # See http://montgomerylab.stanford.edu/resources/kukurba2013/index.html
export bcftools=/data/srlab/slowikow/src/bcftools-1.2/bcftools # Borrowing from Kam due to cluster dependency issues and being shorter on time than I'd like.


# Other apps used in this script.
     # Need to adjust htslib installation to set into custom PATH for dependencies (zlib and glibc) to be properly called.
module load samtools/1.1
module load vcftools/0.1.12
module load BEDTools_2.17 # Note that Piskol scripts expect this to be in PATH, so if it's not, will need to manually edit at least the script for homopolymer nt filtering; maybe others.


# Other options
LC_COLLATE=C


# Notes
	# Export: Variables are inherited by child processes (e.g. subshells from GNU parallel).
     # Bash variables are untyped by default.  For more robust code, can declare data type with [declare] (see http://tldp.org/LDP/abs/html/declareref.html ), but I'm not sure how declare works with export.  May try later.\
     # When possible, using full path in order to record app version (will copy scripts into the directory with the data at the end) and increase clarity regarding dependencies.
     #export queueGATK=$pathApps/queue-3.4-46/Queue.jar # Queue isn't compatible with LSF v9+ (see http://gatkforums.broadinstitute.org/discussion/3162/queue-and-lsf-versions).  As of 2015-09-12, running "lsid" on ERISOne reported "Platform LSF 8.0.1, Jun 13 2011", so it'd work for now, but it seems like a lot of effort to learn this platform if it's already outdated.


#####

echo "Today's date is $(date +%Y-%m-%d)"

# Add newline to output for readability
echo


#####

# EXTRACT USEFUL PREDICTORS (COLUMNS)

# Copy ASE output and marked SNPs to new folder
mkdir ${pathWd}/aaa_finalASEFiles

find "${pathWd}" -type f -name "ASE02f12_*.txt" -print0 | \
     xargs -0 cp -t "${pathWd}/aaa_finalASEFiles"

find "${pathWd}" -type f -name "ASE02f14_5SamASE_*ASE.txt" -print0 | \
     xargs -0 cp -t "${pathWd}/aaa_finalASEFiles"

find "${pathWd}" -type f -name "ASE02f15_dupGroupsScaledTo100_*.txt" -print0 | \
     xargs -0 cp -t "${pathWd}/aaa_finalASEFiles"

find "${pathWd}" -type f -name "ASE02f17_uniqueProblematicSNPs_*.txt" -print0 | \
     xargs -0 cp -t "${pathWd}/aaa_finalASEFiles"


# Notes
     # The find -exec version below works, but the "+" at the end is only defined in GNU (not POSIX) systems, so I swapped it out for xargs (see above command).
          #find ${pathWd} -type f -name "ASE02f13_5SamASE_*.txt" -exec cp -t ${pathWd}/aaa_finalASEFiles '{}' +


#####

# MERGE ASE OUTPUT FILES

# Move to ASE output folder
cd ${pathWd}/aaa_finalASEFiles


# Create ordered list of ASE output files
ls -1 ASE02f14_5SamASE_*.txt > ASE02_aa_listOutput.txt


# Extract columns 1-9 with cut.
$parallel -j ${intCPUs} --joblog --resume-failed --keep-order \
     'sh ${pathSubscripts}/RNA-ASE-03_func01FormatASEOutput.sh' \
     :::: ASE02_aa_listOutput.txt


# Concatenate files while keeping first header line for column names
array=( ASE03f01_trimmed_*.txt )

{ cat ${array[@]:0:1}; grep -hv '^INDIVIDUAL' ${array[@]:1}; } \
     > ASE03f02_mergedASEOutput.txt


# Notes
     # Columns 1-9 are 1) Individual, 2) RSID, 3) Chr, 4) Position, 5) Alleles, 6) Both alleles seen?, 7) Ref count, 8) Nonref count, and 9) total count.  The other columns contain analysis info, which we discard because we analyze it ourselves, and exon annotations, which are a huge mess since the annotation files are a huge mess.
     
     # Concatenation using a bash array slicing technique.  The -h flag suppresses prefixing the filenames on output when searching multiple files; -v flag inverts the grep match; ^ in REGEX means beginning of the string (note that this will remove all lines that start with INDIVIDUAL in the grepped files).  --http://unix.stackexchange.com/questions/60577/concatenate-multiple-files-with-same-header
          # Side benefit: Creating an array this way seems to maintain file order!  Very nifty.
          # Since this is array slicing, I imagine it'd be fairly easy to modify it to create batches of merged analysis files in case we're working with so many individuals that the full merged data file would be too large to easily process.


#####

# ADD COLUMN WITH INDIVIDUAL IDs FROM VALUE IN INDIVIDUAL COLUMN (COLUMN 1)

# Find individual IDs and print into an external file using regular expressions (and implicit BASH_REMATCH) with sed.
grep -o "ASE02f14_3SamParse.*\.txt" ASE03f02_mergedASEOutput.txt | \
     sed -ne 's/ASE02f14_3SamParse\(.*\)ind\.\(.*\)_\(.*\)\.sra\.parsed_pileup\.txt/\2/p' \
     > aaa_outputIndID.txt

# Add column header to file
sed -i '1iIndID' aaa_outputIndID.txt

# Count number of lines in SED output and original file to confirm match
echo
wc --lines ASE03f02_mergedASEOutput.txt aaa_outputIndID.txt

# Add IndID column to ASE output file
paste ASE03f02_mergedASEOutput.txt \
     aaa_outputIndID.txt \
     > ASE03f03_mergedASEOutputWithInd.txt


# Notes
     # This relies on the fact that grep's output matches the order of the searched file as long as there's only one searched file.  So it isn't the most robust way...  It's possible for the order to get messed up since it's not line-by-line.  But I haven't been able to get a while loop to work, so I probably need to learn either Python or Awk to do it right.
     # Should probably learn how to code in a test that results in an exit command if the number of lines for the original file and the new column don't match.


#####

# ADD COLUMN WITH LIBRARIES FROM VALUE IN INDIVIDUAL COLUMN (COLUMN 1)

# Find individual IDs and print into an external file using regular expressions (and implicit BASH_REMATCH) with sed.
grep -o "ASE02f14_3SamParse.*\.txt" ASE03f02_mergedASEOutput.txt | \
     sed -ne 's/ASE02f14_3SamParse\(.*\)ind\.\(.*\)_\(.*\)\.sra\.parsed_pileup\.txt/\3/p' \
     > aaa_outputLibraries.txt

# Add column header to file
sed -i '1iLibrary' aaa_outputLibraries.txt

# Count number of lines in SED output and original file to confirm match
echo
wc --lines ASE03f02_mergedASEOutput.txt aaa_outputLibraries.txt

# Add IndID column to ASE output file
paste ASE03f03_mergedASEOutputWithInd.txt \
     aaa_outputLibraries.txt \
     > ASE03f04_mergedASEOutputWithIndLib.txt


#####

# MERGE VARIANT CALLING AND FILTRATION SUMMARY STATS

# Concatenate files while keeping first header line for column names
array=( ASE02f12_*.txt )

{ cat ${array[@]:0:1}; grep -hv '^File' ${array[@]:1}; } \
     > ASE03f05_mergedVarCallQC.txt



